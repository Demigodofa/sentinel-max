"""LLM backend plumbing for Sentinel MAX.

Supports local Ollama (preferred) or OpenAI-compatible endpoints.
"""

